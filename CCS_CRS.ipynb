{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21a69eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f92ab1f-e574-4089-96cc-6e74ca926d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10f3a93e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import gc\n",
    "import time\n",
    "import torch\n",
    "import numpy\n",
    "import pickle\n",
    "import random\n",
    "import threading\n",
    "import numpy as np\n",
    "import torchvision\n",
    "import scienceplots\n",
    "from numpy import dot\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from functools import partial\n",
    "from numpy.linalg import norm\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rcParams\n",
    "import torch.nn.functional as F \n",
    "import matplotlib.colors as colors\n",
    "from collections import defaultdict\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.nn.functional import normalize\n",
    "from torchvision import datasets, models, transforms\n",
    "\n",
    "from lpips import LPIPS\n",
    "from safetensors import safe_open\n",
    "from diffusers import UNet2DConditionModel\n",
    "from diffusers.utils import make_image_grid\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from torchmetrics.functional.multimodal import clip_score\n",
    "from torchmetrics.image.kid import KernelInceptionDistance\n",
    "from diffusers.pipelines.stable_diffusion import StableDiffusionPipeline, StableDiffusionImg2ImgPipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b375d38-dc67-42d7-aee1-92ba9222bc0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use(['science', 'notebook', 'grid'])\n",
    "\n",
    "plt.rcParams.update({\n",
    "    'font.family': 'serif',\n",
    "    'font.size': 15,\n",
    "    'axes.labelsize': 15,\n",
    "    'xtick.labelsize': 12,\n",
    "    'ytick.labelsize': 12\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f01b6a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 2\n",
    "\n",
    "# Hyperparameters\n",
    "gpu_ids = [0, 1, 2] # List the indices of cuda devices\n",
    "cuda_device='cuda:1' # Main cuda device, the others mentioned above are used for parallel image generation\n",
    "\n",
    "prompt = \"\"\n",
    "finetuned_weights_path = \"\"\n",
    "\n",
    "mul_method = \"\"\n",
    "# mul_method=\"ablating\"\n",
    "# mul_method=\"sdd\"\n",
    "# mul_method=\"erasure\"\n",
    "# mul_method = \"safegen\"\n",
    "\n",
    "retain_set_eval = False\n",
    "\n",
    "original_weights_repo_hf = \"CompVis/stable-diffusion-v1-4\"\n",
    "\n",
    "seed = 42\n",
    "inference_steps = 100\n",
    "guidance_scale=7.5\n",
    "eta=1.\n",
    "device = torch.device(cuda_device)\n",
    "\n",
    "eval_infer_timestep_chkpts = [x / 100.0 for x in range(5, 60, 10)]\n",
    "eval_infer_timestep_chkpts.insert(0, 0.001)\n",
    "eval_infer_timestep_chkpts.insert(1, 0.01)\n",
    "print(eval_infer_timestep_chkpts)\n",
    "\n",
    "eval_set_size = 200\n",
    "\n",
    "image_preprocessor = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5d56579",
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 2\n",
    "\n",
    "# Helper functions\n",
    "\n",
    "def load_frozen_weights(model, save_path, mul_method=\"ablating\") -> None:\n",
    "    if mul_method == \"ablating\":\n",
    "        weights = torch.load(save_path)\n",
    "        if 'text_encoder' in weights:\n",
    "            model.text_encoder.load_state_dict(weights['text_encoder'])\n",
    "        for name, params in model.unet.named_parameters():\n",
    "            if name in weights['unet']:\n",
    "                params.data.copy_(weights['unet'][f'{name}'])\n",
    "    elif mul_method == \"erasure\":\n",
    "        weights = torch.load(save_path)\n",
    "        model.unet.load_state_dict(weights)\n",
    "    elif mul_method == \"sdd\":\n",
    "        dev = model.unet.device\n",
    "        del model.unet\n",
    "        model.unet = UNet2DConditionModel.from_pretrained(save_path).to(dev)\n",
    "    elif mul_method == \"safegen\":\n",
    "        with safe_open(save_path, framework=\"pt\", device=\"cpu\") as f:\n",
    "            for key in f.keys():\n",
    "                if key in model.unet.state_dict():\n",
    "                    model.unet.state_dict()[key].copy_(f.get_tensor(key))\n",
    "\n",
    "def generate_diffusion_pipeline(weights_repo, cuda_device) -> StableDiffusionPipeline:\n",
    "    pipeline = StableDiffusionPipeline.from_pretrained(\n",
    "        weights_repo,\n",
    "        requires_safety_checker=False,\n",
    "        safety_checker=None\n",
    "    ).to(cuda_device)\n",
    "\n",
    "    return pipeline\n",
    "\n",
    "def generate_diffusion_img2img_pipeline(weights_repo, cuda_device) -> StableDiffusionImg2ImgPipeline:\n",
    "    pipeline = StableDiffusionImg2ImgPipeline.from_pretrained(\n",
    "        weights_repo,\n",
    "        requires_safety_checker=False,\n",
    "        safety_checker=None\n",
    "    ).to(cuda_device)\n",
    "\n",
    "    return pipeline\n",
    "\n",
    "def compress_pillow_image(img, output_path, quality=85):\n",
    "  new_width = 400\n",
    "  width, height = img.size\n",
    "  aspect_ratio = width / height\n",
    "  new_height = int(new_width / aspect_ratio)\n",
    "  img = img.resize((new_width, new_height))\n",
    "\n",
    "  img.save(output_path, quality=quality)\n",
    "\n",
    "\n",
    "def print_image_grid(num_images, truth_type):\n",
    "    grid_path = f\"./out/{mul_method}/{prompt}/{truth_type}_ground_truth_grid_{num_images}\"\n",
    "    images = []\n",
    "    for num in range(num_images):\n",
    "        image_path = f\"./out/{mul_method}/{prompt}/{truth_type}_ground_truth_{num}.png\"\n",
    "        image = Image.open(image_path)\n",
    "        images.append(image)\n",
    "    \n",
    "    grid = make_image_grid(images, rows=int(num_images**0.5), cols=int(num_images**0.5))\n",
    "    grid.save(f\"{grid_path}-full-size.png\")\n",
    "    display(grid)\n",
    "    compress_pillow_image(grid, f\"{grid_path}.png\", quality=100)\n",
    "\n",
    "\n",
    "def plot_ground_truth_samples(finetuned_pipeline, original_pipeline, prompt, mul_method, seed):\n",
    "    fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(16, 16))\n",
    "\n",
    "    for i, ax in enumerate(axes.flat):\n",
    "\n",
    "        if i == 0:\n",
    "            ablated_path = f\"out/{mul_method}/{prompt}/ablated_ground_truth_{seed}.png\"\n",
    "            os.makedirs(os.path.dirname(ablated_path), exist_ok=True)\n",
    "\n",
    "            ablated_ground_truth = None\n",
    "\n",
    "            if os.path.exists(ablated_path):\n",
    "                ablated_ground_truth = Image.open(ablated_path)\n",
    "            else:\n",
    "                ablated_ground_truth = finetuned_pipeline(\n",
    "                    prompt=prompt,\n",
    "                    num_inference_steps=inference_steps,\n",
    "                    output_type=\"pil\",\n",
    "                    eta=eta,\n",
    "                    generator=torch.manual_seed(seed)\n",
    "                ).images[0]\n",
    "                ablated_ground_truth.save(ablated_path)\n",
    "\n",
    "\n",
    "            ax.imshow(ablated_ground_truth)\n",
    "            ax.set_title(\"Ablated ground truth\")\n",
    "\n",
    "        elif i == 1:\n",
    "            original_path = f\"out/{mul_method}/{prompt}/original_ground_truth_{seed}.png\"\n",
    "            original_ground_truth = None\n",
    "\n",
    "\n",
    "            if os.path.exists(original_path):\n",
    "                original_ground_truth = Image.open(original_path)\n",
    "            else:\n",
    "                original_ground_truth = original_pipeline(\n",
    "                    prompt=prompt,\n",
    "                    num_inference_steps=inference_steps,\n",
    "                    output_type=\"pil\",\n",
    "                    eta=eta,\n",
    "                    generator=torch.manual_seed(seed)\n",
    "                ).images[0]\n",
    "\n",
    "                original_ground_truth.save(original_path)\n",
    "\n",
    "\n",
    "            ax.imshow(original_ground_truth)\n",
    "            ax.set_title(\"Original Domain Knowledge\")\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "def plot_denoised_iterations(original_pipeline, finetuned_i2i_pipeline, prompt, mul_method, eval_infer_timestep_chkpts):\n",
    "    num_rows = 2\n",
    "    num_cols = len(eval_infer_timestep_chkpts)\n",
    "\n",
    "    eval_image_name = f\"{mul_method}/{prompt}\"\n",
    "\n",
    "    fig, axes = plt.subplots(nrows=num_rows, ncols=num_cols, figsize=(20, 7))\n",
    "    fig.subplots_adjust(hspace=0.5)\n",
    "\n",
    "    os.makedirs('./out', exist_ok=True)\n",
    "\n",
    "    for i, eval_infer_chkpt in enumerate(eval_infer_timestep_chkpts):\n",
    "        if os.path.exists(f\"out/{eval_image_name}/noised-{eval_infer_chkpt}.png\"):\n",
    "            axes[0, i].imshow(Image.open(f\"out/{eval_image_name}/noised-{eval_infer_chkpt}.png\"))\n",
    "            axes[0, i].set_title(f\"Denoised {round(eval_infer_chkpt*100, 2)}%\")\n",
    "            axes[0, i].set_xticks([])\n",
    "            axes[0, i].set_yticks([])\n",
    "            axes[0, i].set_xticklabels([])\n",
    "            axes[0, i].set_yticklabels([])\n",
    "\n",
    "            if os.path.exists(f\"out/{eval_image_name}/denoised-{eval_infer_chkpt}.png\"):\n",
    "                axes[1, i].imshow(Image.open(f\"out/{eval_image_name}/denoised-{eval_infer_chkpt}.png\"))\n",
    "                axes[1, i].set_title(f\"Denoised {round((1-eval_infer_chkpt)*100, 2)}%\")\n",
    "                axes[1, i].set_xticks([])\n",
    "                axes[1, i].set_yticks([])\n",
    "                axes[1, i].set_xticklabels([])\n",
    "                axes[1, i].set_yticklabels([])\n",
    "            continue\n",
    "\n",
    "        noisy_sample = original_pipeline(\n",
    "            prompt=prompt,\n",
    "            num_inference_steps=inference_steps,\n",
    "\n",
    "            denoising_end=eval_infer_chkpt,\n",
    "            output_type=\"latent\",\n",
    "\n",
    "            eta=eta,\n",
    "            generator=torch.manual_seed(seed),\n",
    "        ).images\n",
    "\n",
    "        noisy_image = original_pipeline.image_processor.postprocess(noisy_sample, output_type=\"pil\", do_denormalize=([True] * noisy_sample.shape[0]))[0]\n",
    "        noisy_image.save(f\"out/{eval_image_name}/noised-{eval_infer_chkpt}.png\")\n",
    "\n",
    "        axes[0, i].imshow(noisy_image)\n",
    "        axes[0, i].set_title(f\"Denoised {round(eval_infer_chkpt*100, 2)}% of T\")\n",
    "        axes[0, i].set_xticks([])\n",
    "        axes[0, i].set_yticks([])\n",
    "        axes[0, i].set_xticklabels([])\n",
    "        axes[0, i].set_yticklabels([])\n",
    "        axes[0, i].axis('off')\n",
    "\n",
    "        denoised_image = finetuned_i2i_pipeline(\n",
    "            prompt=prompt,\n",
    "            num_inference_steps=inference_steps,\n",
    "            guidance_scale=guidance_scale,\n",
    "            eta=eta,\n",
    "            generator=torch.manual_seed(seed),\n",
    "            denoising_start=eval_infer_chkpt,\n",
    "\n",
    "            image=noisy_sample\n",
    "        ).images[0]\n",
    "\n",
    "        denoised_image.save(f\"out/{eval_image_name}/denoised-{eval_infer_chkpt}.png\")\n",
    "\n",
    "        axes[1, i].imshow(denoised_image)\n",
    "        axes[1, i].set_title(f\"Denoised {round((1-eval_infer_chkpt)*100, 2)}% of T\")\n",
    "        axes[1, i].set_xticks([])\n",
    "        axes[1, i].set_yticks([])\n",
    "        axes[1, i].set_xticklabels([])\n",
    "        axes[1, i].set_yticklabels([])\n",
    "        axes[1, i].axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"out/{eval_image_name}/denoised_grid.png\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def generate_ground_truth_eval_set(gpus, set_count, gen_prompt, ground_truth_type, ablated=False):\n",
    "    os.makedirs('./out', exist_ok=True)\n",
    "    total_seeds = set_count\n",
    "\n",
    "\n",
    "    def generate_image_range(start_seed, end_seed, gpu_id, pipeline):\n",
    "        for seed in range(start_seed, end_seed):\n",
    "            output_path = f\"out/{mul_method}/{prompt}/{ground_truth_type}_ground_truth_{seed}.png\"\n",
    "            if not os.path.exists(output_path):\n",
    "                original_ground_truth = pipeline(\n",
    "                    prompt=gen_prompt,\n",
    "                    num_inference_steps=inference_steps,\n",
    "                    output_type=\"pil\",\n",
    "\n",
    "                    eta=eta,\n",
    "                    generator=torch.manual_seed(seed)\n",
    "                ).images[0]\n",
    "                original_ground_truth.save(output_path)\n",
    "\n",
    "\n",
    "\n",
    "    # Split seeds across GPUs\n",
    "    seeds_per_gpu = total_seeds // len(gpus)\n",
    "    seed_ranges = [(start, start + seeds_per_gpu) for start in range(0, total_seeds, seeds_per_gpu)]\n",
    "\n",
    "    # Handle any remaining seeds\n",
    "    remaining_seeds = total_seeds % len(gpus)\n",
    "    if remaining_seeds > 0:\n",
    "        seed_ranges[-1] = (seed_ranges[-1][0], seed_ranges[-1][1] + remaining_seeds)\n",
    "\n",
    "\n",
    "    pipelines = []\n",
    "    for gpu_id in gpus:\n",
    "        pipe = generate_diffusion_pipeline(original_weights_repo_hf, f\"cuda:{gpu_id}\")\n",
    "        if ablated:\n",
    "            load_frozen_weights(pipe, finetuned_weights_path, mul_method)\n",
    "        pipelines.append(pipe)\n",
    "\n",
    "    threads = []\n",
    "    for gpu_id, (start_seed, end_seed), pipeline in zip(range(len(gpus)), seed_ranges, pipelines):\n",
    "        t = threading.Thread(target=generate_image_range, args=(start_seed, end_seed, gpu_id, pipeline))\n",
    "        t.start()\n",
    "        threads.append(t)\n",
    "\n",
    "\n",
    "    for t in threads:\n",
    "        t.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b152051d-2e1e-4757-bd2c-4c3a6f1b3720",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_unlearning(sim_original, sim_ablated, retain_set=False):    \n",
    "    assert len(sim_original) == len(sim_ablated)\n",
    "\n",
    "    differences = []\n",
    "\n",
    "    for i in range(len(sim_original)):\n",
    "        if retain_set:\n",
    "            similarity_diff = abs(sim_original[i] - sim_ablated[i])\n",
    "            differences.append(similarity_diff)\n",
    "        else:\n",
    "            diff = abs(sim_ablated[i] - sim_original[i])\n",
    "            differences.append(diff)\n",
    "\n",
    "    average_diff = sum(differences) / len(differences)\n",
    "\n",
    "    if retain_set:\n",
    "        normalized_score = (1 - average_diff)\n",
    "    else:\n",
    "        normalized_score = average_diff\n",
    "\n",
    "\n",
    "    return normalized_score\n",
    "\n",
    "def calculate_scores(expr_name, x_axis, y_axis, prompt, mul_method, func, eval_set_size, feature_extractor, model, cuda_device):\n",
    "    if func == calculate_kid_score:\n",
    "        score1_list = func(cuda_device, \"original\", eval_set_size)\n",
    "        score2_list = func(cuda_device, \"ablated\", eval_set_size)\n",
    "\n",
    "        return score1_list, score2_list\n",
    "    elif func == get_cosine_similarity_batched:\n",
    "        score1_list = []\n",
    "        score2_list = []\n",
    "        for chkpt in tqdm(eval_infer_timestep_chkpts, desc=\"Calculating\"):\n",
    "            denoised_paths = [f\"./out/{mul_method}/{prompt}/denoised-{chkpt}.png\" for seed in range(eval_set_size)]\n",
    "            original_paths = [f\"./out/{mul_method}/{prompt}/original_ground_truth_{seed}.png\" for seed in range(eval_set_size)]\n",
    "            ablated_paths = [f\"./out/{mul_method}/{prompt}/ablated_ground_truth_{seed}.png\" for seed in range(eval_set_size)]\n",
    "    \n",
    "            original_scores_chkpt = func(feature_extractor, image_preprocessor, cuda_device, denoised_paths, original_paths)\n",
    "            ablated_scores_chkpt = func(feature_extractor, image_preprocessor, cuda_device, denoised_paths, ablated_paths)\n",
    "    \n",
    "            score1_list.append(np.mean(original_scores_chkpt))\n",
    "            score2_list.append(np.mean(ablated_scores_chkpt))\n",
    "\n",
    "        print(f\"CRS {func.__name__}: {evaluate_unlearning(score1_list, score2_list, retain_set=retain_set_eval)}\")\n",
    "        \n",
    "        return score1_list, score2_list\n",
    "    elif func == get_denoised_img_pred_scores:\n",
    "        score1_list = []\n",
    "        score2_list = []\n",
    "        \n",
    "        for chkpt in eval_infer_timestep_chkpts:\n",
    "            denoised_path = f\"./out/{mul_method}/{prompt}/denoised-{chkpt}.png\"\n",
    "            prob = get_denoised_img_pred_scores(denoised_path, model, image_preprocessor, cuda_device)\n",
    "            score1_list.append(prob)\n",
    "            score2_list.append(1-prob)\n",
    "        \n",
    "        print(f\"CCS: {np.mean(score1_list) * 100}\")\n",
    "        return score1_list, score2_list\n",
    "    else:\n",
    "        score1_list = []\n",
    "        score2_list = []\n",
    "\n",
    "        for i in eval_infer_timestep_chkpts:\n",
    "            score1 = func(feature_extractor, image_preprocessor, cuda_device, f\"out/{mul_method}/{prompt}/denoised-{i}.png\", f\"out/{mul_method}/{prompt}/original_ground_truth_{seed}.png\")\n",
    "            score2 = func(feature_extractor, image_preprocessor, cuda_device, f\"out/{mul_method}/{prompt}/denoised-{i}.png\", f\"out/{mul_method}/{prompt}/ablated_ground_truth_{seed}.png\")\n",
    "\n",
    "            score1_list.append(score1.item())\n",
    "            score2_list.append(score2.item())\n",
    "\n",
    "\n",
    "        return score1_list, score2_list\n",
    "\n",
    "\n",
    "def plot_grid(prompt, mul_method, cuda_device, eval_set_size, model_name, plot_cases):\n",
    "    num_cases = len(plot_cases)\n",
    "    nrows = (num_cases + 1) // 2  # Calculate the number of rows needed\n",
    "    ncols = 2 if num_cases > 1 else 1  # Set the number of columns to 2 if there are multiple cases, else 1\n",
    "\n",
    "    # Calculate the figure size based on the number of cases\n",
    "    fig_width = ncols * 6\n",
    "    fig_height = nrows * 6\n",
    "    fig, axes = plt.subplots(nrows=nrows, ncols=ncols, figsize=(fig_width, fig_height))\n",
    "\n",
    "    if num_cases > 1:\n",
    "        axes = axes.flatten()  # Flatten the axes if there are multiple cases\n",
    "\n",
    "    def calculate_scores_thread(i, case):\n",
    "        expr_name, x_axis, y_axis, func, model, feature_extractor = case\n",
    "        score1_list, score2_list = calculate_scores(expr_name, x_axis, y_axis, prompt, mul_method, func, eval_set_size, feature_extractor, model, cuda_device)\n",
    "\n",
    "        if num_cases > 1:\n",
    "            ax = axes[i]  # Get the corresponding axis for the current case\n",
    "        else:\n",
    "            ax = axes  # Use the single axis if there is only one case\n",
    "\n",
    "        if len(score1_list) > 0:\n",
    "            if len(score2_list) == 0:\n",
    "                ax.plot(eval_infer_timestep_chkpts, score1_list, 'o--')\n",
    "            else:\n",
    "                ax.plot(eval_infer_timestep_chkpts, score1_list, 'o--', label='Original Domain Knowledge')\n",
    "        if len(score2_list) > 0:\n",
    "            ax.plot(eval_infer_timestep_chkpts, score2_list, 'o--', label='Unlearned Domain Knowledge')\n",
    "\n",
    "        ax.set_xlabel(x_axis)\n",
    "        ax.set_ylabel(y_axis)\n",
    "        ax.set_title(expr_name)\n",
    "        ax.legend()\n",
    "\n",
    "        # Create the directory if it doesn't exist\n",
    "        output_dir = f\"./out/{mul_method}/{prompt}/\"\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "        # Save the subplot as a separate PDF file\n",
    "        subplot_filename = os.path.join(output_dir, f\"{func.__name__}_{model_name}.pdf\")\n",
    "        fig_subplot = plt.figure(figsize=(6, 6))\n",
    "        ax_subplot = fig_subplot.add_subplot(111)\n",
    "        if len(score1_list) > 0:\n",
    "            if len(score2_list) == 0:\n",
    "                ax_subplot.plot(eval_infer_timestep_chkpts, score1_list, 'o--')\n",
    "            else:\n",
    "                ax_subplot.plot(eval_infer_timestep_chkpts, score1_list, 'o--', label='Original Domain Knowledge')\n",
    "        if len(score2_list) > 0:\n",
    "            ax_subplot.plot(eval_infer_timestep_chkpts, score2_list, 'o--', label='Unlearned Domain Knowledge')\n",
    "        ax_subplot.set_xlabel(x_axis)\n",
    "        ax_subplot.set_ylabel(y_axis)\n",
    "        ax_subplot.set_title(expr_name)\n",
    "        ax_subplot.legend()\n",
    "        fig_subplot.savefig(subplot_filename)\n",
    "        plt.close(fig_subplot)\n",
    "\n",
    "    threads = []\n",
    "    for i, case in enumerate(plot_cases):\n",
    "        thread = threading.Thread(target=calculate_scores_thread, args=(i, case))\n",
    "        thread.start()\n",
    "        threads.append(thread)\n",
    "\n",
    "    for thread in threads:\n",
    "        thread.join()\n",
    "\n",
    "    # Adjust spacing between subplots\n",
    "    plt.subplots_adjust(wspace=0.3, hspace=0.3)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Save the full plot as \"scores.pdf\" in the specified directory\n",
    "    full_plot_filename = f\"./out/{mul_method}/{prompt}/{model_name}-scores.pdf\"\n",
    "    fig.savefig(full_plot_filename)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "def calculate_kid_score(cuda_device, ground_truth_type, ground_truth_set_size=200, device=None):\n",
    "    device = torch.device(cuda_device)\n",
    "\n",
    "    preprocess = transforms.Compose([\n",
    "        image_preprocessor,\n",
    "        transforms.Resize((299, 299)),\n",
    "        lambda x: (x * 255).to(torch.uint8)  # Convert to uint8 after normalization\n",
    "    ])\n",
    "\n",
    "    kid_scorer = KernelInceptionDistance(subset_size=ground_truth_set_size).to(device)\n",
    "\n",
    "    # Load ground truth images\n",
    "    ground_truth_images = []\n",
    "    for j in tqdm(range(ground_truth_set_size), desc='Loading ground truth images'):\n",
    "        image_path = os.path.join(f\"out/{mul_method}/{prompt}/{ground_truth_type}_ground_truth_{j}.png\")\n",
    "        image = Image.open(image_path).convert('RGB')\n",
    "        ground_truth_images.append(preprocess(image))\n",
    "\n",
    "    ground_truth_images = torch.stack(ground_truth_images).to(device)\n",
    "\n",
    "    kid_scores = []\n",
    "\n",
    "    for chkpt in tqdm(eval_infer_timestep_chkpts, desc='Processing checkpoints'):\n",
    "        # Load denoised image\n",
    "        denoised_image_path = os.path.join(f\"out/{mul_method}/{prompt}/denoised-{chkpt}.png\")\n",
    "        denoised_image = Image.open(denoised_image_path).convert('RGB')\n",
    "        denoised_image = preprocess(denoised_image)\n",
    "        denoised_images = denoised_image.repeat(ground_truth_set_size, 1, 1, 1)\n",
    "        denoised_images = denoised_images.to(device)\n",
    "\n",
    "        kid_scorer.update(ground_truth_images, real=True)\n",
    "        kid_scorer.update(denoised_images, real=False)\n",
    "\n",
    "        kid_score, _ = kid_scorer.compute()\n",
    "        kid_scores.append(kid_score.item())\n",
    "\n",
    "        del denoised_images\n",
    "        gc.collect()\n",
    "    return kid_scores\n",
    "\n",
    "\n",
    "\n",
    "def get_cosine_similarity(feature_extractor, image_preprocessor, device, src1, src2):\n",
    "    # Preprocess images and send them to the device\n",
    "    image1 = image_preprocessor(Image.open(src1)).unsqueeze(0).to(device)\n",
    "    image2 = image_preprocessor(Image.open(src2)).unsqueeze(0).to(device)\n",
    "    \n",
    "    feature_extractor.eval()\n",
    "    feature_extractor.to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # Get feature vectors, squeeze out extra dimensions if needed\n",
    "        feature_vector_1 = feature_extractor(image1).squeeze()\n",
    "        feature_vector_2 = feature_extractor(image2).squeeze()\n",
    "\n",
    "        # Normalize feature vectors\n",
    "        feature_vector_1 = nn.functional.normalize(feature_vector_1, dim=0)\n",
    "        feature_vector_2 = nn.functional.normalize(feature_vector_2, dim=0)\n",
    "\n",
    "        # Calculate cosine similarity\n",
    "        cos_sim = (feature_vector_1 @ feature_vector_2.T).squeeze()\n",
    "        sim = (1 - torch.arctan(cos_sim)) / (np.pi / 2)\n",
    "\n",
    "    return sim.detach().cpu().numpy()\n",
    "\n",
    "def get_cosine_similarity_batched(feature_extractor, image_preprocessor, device, denoised_paths, target_paths):\n",
    "    # Preprocess and load images\n",
    "    denoised_images = [image_preprocessor(Image.open(path)).unsqueeze(0).to(device) for path in denoised_paths]\n",
    "    target_images = [image_preprocessor(Image.open(path)).unsqueeze(0).to(device) for path in target_paths]\n",
    "\n",
    "    # Concatenate all images into batches\n",
    "    denoised_batch = torch.cat(denoised_images, dim=0)\n",
    "    target_batch = torch.cat(target_images, dim=0)\n",
    "\n",
    "    feature_extractor.eval()\n",
    "    feature_extractor.to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # Extract features and remove extra dimensions if needed\n",
    "        denoised_features = feature_extractor(denoised_batch)\n",
    "        target_features = feature_extractor(target_batch)\n",
    "\n",
    "        # Squeeze out extra spatial dimensions if they exist\n",
    "        if denoised_features.dim() > 2:\n",
    "            denoised_features = denoised_features.squeeze(dim=(2, 3))\n",
    "            target_features = target_features.squeeze(dim=(2, 3))\n",
    "\n",
    "        # Normalize feature vectors\n",
    "        denoised_features = F.normalize(denoised_features, dim=1)\n",
    "        target_features = F.normalize(target_features, dim=1)\n",
    "\n",
    "        # Compute cosine similarities for each pair\n",
    "        cos_sim_matrix = torch.matmul(denoised_features, target_features.T)\n",
    "        sim_matrix = (1 - torch.arctan(cos_sim_matrix)) / (np.pi / 2)\n",
    "\n",
    "        # Calculate mean similarity from the diagonal\n",
    "        sim_mean = sim_matrix.diagonal().mean().item()\n",
    "\n",
    "    return sim_mean\n",
    "\n",
    "\n",
    "def get_denoised_img_pred_scores(denoised_path, model, image_preprocessor, cuda_device):\n",
    "    device = torch.device(cuda_device)\n",
    "    model.eval()\n",
    "\n",
    "    denoised_image = image_preprocessor(Image.open(denoised_path)).unsqueeze(0).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(denoised_image)\n",
    "        probs = nn.Softmax(dim=1)(outputs)[:, 1]  # Probability of being the original ground truth\n",
    "\n",
    "    return probs.item()\n",
    "\n",
    "def finetune_model_with_contrastive_learning(prompt, mul_method, eval_set_size, cuda_device, image_preprocessor, model_name):\n",
    "    # Define Triplet Dataset class with hard negative mining\n",
    "    class TripletDataset(torch.utils.data.Dataset):\n",
    "        def __init__(self, image_paths, labels, transform, num_negatives=3):\n",
    "            self.image_paths = image_paths\n",
    "            self.labels = labels\n",
    "            self.transform = transform\n",
    "            self.num_negatives = num_negatives\n",
    "            self.label_to_indices = defaultdict(list)\n",
    "            for idx, label in enumerate(self.labels):\n",
    "                self.label_to_indices[label].append(idx)\n",
    "\n",
    "        def __getitem__(self, index):\n",
    "            anchor_path = self.image_paths[index]\n",
    "            anchor_label = self.labels[index]\n",
    "            anchor_image = Image.open(anchor_path).convert('RGB')\n",
    "            anchor_image = self.transform(anchor_image)\n",
    "\n",
    "            # Select positive sample from same class, avoiding identical images\n",
    "            positive_indices = [i for i in self.label_to_indices[anchor_label] if i != index]\n",
    "            if not positive_indices:\n",
    "                positive_index = index\n",
    "            else:\n",
    "                positive_index = random.choice(positive_indices)\n",
    "            \n",
    "            positive_path = self.image_paths[positive_index]\n",
    "            positive_image = Image.open(positive_path).convert('RGB')\n",
    "            positive_image = self.transform(positive_image)\n",
    "\n",
    "            # Select negative samples\n",
    "            negative_label = 1 - anchor_label  # Assuming binary labels\n",
    "            negative_indices = random.sample(self.label_to_indices[negative_label], \n",
    "                                             min(self.num_negatives, len(self.label_to_indices[negative_label])))\n",
    "            \n",
    "            negative_images = []\n",
    "            for neg_idx in negative_indices:\n",
    "                negative_path = self.image_paths[neg_idx]\n",
    "                negative_image = Image.open(negative_path).convert('RGB')\n",
    "                negative_images.append(self.transform(negative_image))\n",
    "\n",
    "            # If we don't have enough negative samples, duplicate the last one\n",
    "            while len(negative_images) < self.num_negatives:\n",
    "                negative_images.append(negative_images[-1])\n",
    "\n",
    "            return anchor_image, positive_image, torch.stack(negative_images), anchor_label\n",
    "\n",
    "        def __len__(self):\n",
    "            return len(self.image_paths)\n",
    "\n",
    "    # Standard dataset remains the same\n",
    "    class StandardDataset(torch.utils.data.Dataset):\n",
    "        def __init__(self, image_paths, labels, transform):\n",
    "            self.image_paths = image_paths\n",
    "            self.labels = labels\n",
    "            self.transform = transform\n",
    "\n",
    "        def __getitem__(self, index):\n",
    "            image_path = self.image_paths[index]\n",
    "            image = Image.open(image_path).convert('RGB')\n",
    "            image = self.transform(image)\n",
    "            label = self.labels[index]\n",
    "            return image, label\n",
    "\n",
    "        def __len__(self):\n",
    "            return len(self.image_paths)\n",
    "\n",
    "    # Create datasets\n",
    "    ablated_paths = [f\"./out/{mul_method}/{prompt}/ablated_ground_truth_{seed}.png\" for seed in range(eval_set_size)]\n",
    "    original_paths = [f\"./out/{mul_method}/{prompt}/original_ground_truth_{seed}.png\" for seed in range(eval_set_size)]\n",
    "\n",
    "    ablated_labels = [0] * eval_set_size\n",
    "    original_labels = [1] * eval_set_size\n",
    "\n",
    "    image_paths = ablated_paths + original_paths\n",
    "    labels = ablated_labels + original_labels\n",
    "\n",
    "    # Split indices for train and validation\n",
    "    dataset_size = len(image_paths)\n",
    "    indices = list(range(dataset_size))\n",
    "    split = int(np.floor(0.2 * dataset_size))\n",
    "    np.random.shuffle(indices)\n",
    "    train_indices, val_indices = indices[split:], indices[:split]\n",
    "\n",
    "    # Create datasets\n",
    "    train_dataset = TripletDataset([image_paths[i] for i in train_indices], \n",
    "                                   [labels[i] for i in train_indices], \n",
    "                                   image_preprocessor)\n",
    "    val_dataset = StandardDataset([image_paths[i] for i in val_indices], \n",
    "                                  [labels[i] for i in val_indices], \n",
    "                                  image_preprocessor)\n",
    "\n",
    "    # Create data loaders\n",
    "    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "    # Initialize model and move to device\n",
    "    device = torch.device(cuda_device)\n",
    "    if model_name == 'densenet':\n",
    "        model = models.densenet121(weights='IMAGENET1K_V1')\n",
    "        num_ftrs = model.classifier.in_features\n",
    "        model.classifier = nn.Linear(num_ftrs, 2)\n",
    "    elif model_name == 'efficientnet':\n",
    "        model = models.efficientnet_b0(weights='IMAGENET1K_V1')\n",
    "        num_ftrs = model.classifier[1].in_features\n",
    "        model.classifier[1] = nn.Linear(num_ftrs, 2)\n",
    "    elif model_name == 'resnet':\n",
    "        model = models.resnet18(weights='IMAGENET1K_V1')\n",
    "        num_ftrs = model.fc.in_features\n",
    "        model.fc = nn.Linear(num_ftrs, 2)\n",
    "    else:\n",
    "        raise ValueError(\"Model name must be 'densenet', 'efficientnet', or 'resnet'.\")\n",
    "\n",
    "    model = model.to(device)\n",
    "\n",
    "    # Define a function to extract features\n",
    "    def extract_features(model, x):\n",
    "        if model_name == 'densenet':\n",
    "            features = model.features(x)\n",
    "            out = nn.functional.relu(features, inplace=True)\n",
    "            out = nn.functional.adaptive_avg_pool2d(out, (1, 1))\n",
    "            out = torch.flatten(out, 1)\n",
    "        elif model_name == 'efficientnet':\n",
    "            features = model.features(x)\n",
    "            out = nn.functional.adaptive_avg_pool2d(features, (1, 1))\n",
    "            out = torch.flatten(out, 1)\n",
    "        elif model_name == 'resnet':\n",
    "            x = model.conv1(x)\n",
    "            x = model.bn1(x)\n",
    "            x = model.relu(x)\n",
    "            x = model.maxpool(x)\n",
    "    \n",
    "            x = model.layer1(x)\n",
    "            x = model.layer2(x)\n",
    "            x = model.layer3(x)\n",
    "            x = model.layer4(x)\n",
    "    \n",
    "            x = model.avgpool(x)\n",
    "            x = torch.flatten(x, 1)\n",
    "            out = x\n",
    "        else:\n",
    "            raise ValueError(\"Model name must be 'densenet', 'efficientnet', or 'resnet'.\")\n",
    "        return out\n",
    "    \n",
    "    # Define improved triplet loss\n",
    "    class TripletLoss(nn.Module):\n",
    "        def __init__(self, margin=1.0):\n",
    "            super(TripletLoss, self).__init__()\n",
    "            self.margin = margin\n",
    "        \n",
    "        def forward(self, anchor, positive, negatives):\n",
    "            positive_dist = torch.norm(anchor - positive, dim=1)\n",
    "            negative_dists = torch.norm(anchor.unsqueeze(1) - negatives, dim=2)\n",
    "            hardest_negative_dist, _ = torch.min(negative_dists, dim=1)\n",
    "            loss = torch.clamp(positive_dist - hardest_negative_dist + self.margin, min=0.0)\n",
    "            return loss.mean()\n",
    "\n",
    "    # Define loss functions and optimizer\n",
    "    triplet_criterion = TripletLoss(margin=1.0)\n",
    "    classification_criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "    # Training loop\n",
    "    num_epochs = 10\n",
    "    train_total_losses = []\n",
    "    train_triplet_losses = []\n",
    "    train_classification_losses = []\n",
    "    val_accuracies = []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        running_triplet_loss = 0.0\n",
    "        running_classification_loss = 0.0\n",
    "\n",
    "        model.train()\n",
    "        for anchor, positive, negatives, labels in train_loader:\n",
    "            anchor, positive, negatives, labels = anchor.to(device), positive.to(device), negatives.to(device), labels.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Extract features\n",
    "            anchor_features = extract_features(model, anchor)\n",
    "            positive_features = extract_features(model, positive)\n",
    "            \n",
    "            # Process negative samples\n",
    "            batch_size, num_negatives, C, H, W = negatives.size()\n",
    "            negatives_reshaped = negatives.view(-1, C, H, W)\n",
    "            negative_features = extract_features(model, negatives_reshaped)\n",
    "            negative_features = negative_features.view(batch_size, num_negatives, -1)\n",
    "\n",
    "            # Compute losses\n",
    "            triplet_loss = triplet_criterion(anchor_features, positive_features, negative_features)\n",
    "            if model_name == 'densenet' or model_name == 'efficientnet':\n",
    "                classification_outputs = model.classifier(anchor_features)\n",
    "            elif model_name == 'resnet':\n",
    "                classification_outputs = model.fc(anchor_features)\n",
    "            classification_loss = classification_criterion(classification_outputs, labels)\n",
    "            total_loss = triplet_loss + classification_loss\n",
    "\n",
    "            # Backward pass\n",
    "            total_loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += total_loss.item()\n",
    "            running_triplet_loss += triplet_loss.item()\n",
    "            running_classification_loss += classification_loss.item()\n",
    "\n",
    "        # Calculate epoch losses\n",
    "        epoch_loss = running_loss / len(train_loader)\n",
    "        epoch_triplet_loss = running_triplet_loss / len(train_loader)\n",
    "        epoch_classification_loss = running_classification_loss / len(train_loader)\n",
    "\n",
    "        train_total_losses.append(epoch_loss)\n",
    "        train_triplet_losses.append(epoch_triplet_loss)\n",
    "        train_classification_losses.append(epoch_classification_loss)\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "        print(f\"Total Loss: {epoch_loss:.4f}, Triplet Loss: {epoch_triplet_loss:.4f}, Classification Loss: {epoch_classification_loss:.4f}\")\n",
    "\n",
    "        # Validation\n",
    "        model.eval()\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_loader:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                outputs = model(inputs)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "\n",
    "        val_accuracy = 100 * correct / total\n",
    "        val_accuracies.append(val_accuracy)\n",
    "        print(f\"Validation Accuracy: {val_accuracy:.2f}%\")\n",
    "\n",
    "    # Save plots\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(range(1, num_epochs+1), train_total_losses, 'o--', label='Total Loss')\n",
    "    plt.plot(range(1, num_epochs+1), train_triplet_losses, 'o--', label='Triplet Loss')\n",
    "    plt.plot(range(1, num_epochs+1), train_classification_losses, 'o--', label='Classification Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Training Losses')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(range(1, num_epochs+1), val_accuracies, 'o--', label='Validation Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy (%)')\n",
    "    plt.title('Validation Accuracy')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    os.makedirs(f\"out/{mul_method}/{prompt}/\", exist_ok=True)\n",
    "    plt.savefig(f\"out/{mul_method}/{prompt}/{eval_set_size}-training_curves-{model_name}.pdf\")\n",
    "    plt.show()\n",
    "    \n",
    "    # Save model state dict without modification\n",
    "    torch.save(model.state_dict(), f\"out/{mul_method}/{prompt}/{eval_set_size}-finetuned_model-{model_name}.pth\")\n",
    "\n",
    "def load_model(prompt, mul_method, eval_set_size, cuda_device, image_preprocessor, model_name):\n",
    "    device = torch.device(cuda_device)\n",
    "    weights_file = f\"./out/{mul_method}/{prompt}/{eval_set_size}-finetuned_model-{model_name}.pth\"\n",
    "\n",
    "    if not os.path.exists(weights_file):\n",
    "        print(f\"Weights file {weights_file} does not exist. Fine-tuning the model...\")\n",
    "        finetune_model_with_contrastive_learning(prompt, mul_method, eval_set_size, cuda_device, image_preprocessor, model_name)\n",
    "\n",
    "    if model_name == 'densenet':\n",
    "        model = models.densenet121(pretrained=False)\n",
    "        num_ftrs = model.classifier.in_features\n",
    "        model.classifier = nn.Linear(num_ftrs, 2)\n",
    "    elif model_name == 'efficientnet':\n",
    "        model = models.efficientnet_b0(pretrained=False)\n",
    "        num_ftrs = model.classifier[1].in_features\n",
    "        model.classifier[1] = nn.Linear(num_ftrs, 2)\n",
    "    elif model_name == 'resnet':\n",
    "        model = models.resnet18(pretrained=False)\n",
    "        num_ftrs = model.fc.in_features\n",
    "        model.fc = nn.Linear(num_ftrs, 2)\n",
    "    else:\n",
    "        raise ValueError(\"Model name must be 'densenet', 'efficientnet', or 'resnet'.\")\n",
    "\n",
    "    model.load_state_dict(torch.load(weights_file, map_location=cuda_device))\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    if model_name == 'densenet':\n",
    "        feature_extractor = nn.Sequential(\n",
    "            model.features,\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.AdaptiveAvgPool2d((1, 1)),\n",
    "            nn.Flatten(1)\n",
    "        )\n",
    "    elif model_name == 'efficientnet':\n",
    "        feature_extractor = nn.Sequential(\n",
    "            model.features,\n",
    "            nn.AdaptiveAvgPool2d((1, 1)),\n",
    "            nn.Flatten(1)\n",
    "        )\n",
    "    elif model_name == 'resnet':\n",
    "        feature_extractor = nn.Sequential(\n",
    "            *list(model.children())[:-1],  # All layers except the final classification layer\n",
    "            nn.Flatten(1)\n",
    "        )\n",
    "    else:\n",
    "        raise ValueError(\"Model name must be 'densenet', 'efficientnet', or 'resnet'.\")\n",
    "    \n",
    "    feature_extractor.eval()\n",
    "    feature_extractor.to(device)  # Ensure feature extractor is on the correct device\n",
    "\n",
    "    return model, feature_extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15302b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 2\n",
    "\n",
    "original_pipeline = generate_diffusion_pipeline(original_weights_repo_hf, cuda_device)\n",
    "finetuned_i2i_pipeline = generate_diffusion_img2img_pipeline(original_weights_repo_hf, cuda_device)\n",
    "finetuned_pipeline = generate_diffusion_pipeline(original_weights_repo_hf, cuda_device)\n",
    "\n",
    "load_frozen_weights(finetuned_i2i_pipeline, finetuned_weights_path, mul_method)\n",
    "load_frozen_weights(finetuned_pipeline, finetuned_weights_path, mul_method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "673044b4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%autoreload 2\n",
    "plot_ground_truth_samples(finetuned_pipeline, original_pipeline, prompt, mul_method, seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f591ce80",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_denoised_iterations(original_pipeline, finetuned_i2i_pipeline, prompt, mul_method, eval_infer_timestep_chkpts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc1b1080",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "eval_set_size += 5\n",
    "generate_ground_truth_eval_set(gpu_ids, eval_set_size, prompt, \"original\", ablated=False)\n",
    "generate_ground_truth_eval_set(gpu_ids, eval_set_size, prompt, \"ablated\", ablated=True)\n",
    "eval_set_size -= 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b73f6de0-850e-4e3e-8814-596b9cf7f2b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_image_grid(25, \"original\")\n",
    "print_image_grid(25, \"ablated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eca3486-0c66-426c-9380-22004124223a",
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet_model, resnet_feature_extractor = load_model(prompt, mul_method, eval_set_size, cuda_device, image_preprocessor, model_name='resnet')\n",
    "plot_cases = (\n",
    "    (\"ResNet18 Finetuned (Prefinal-layer)\", \"Partial Diffusion Ratio\", \"Cosine Similarity\", get_cosine_similarity, None, resnet_feature_extractor),\n",
    "    (\"ResNet18 Finetuned (Prefinal-layer)\", \"Partial Diffusion Ratio\", \"Mean Cosine Similarity\", get_cosine_similarity_batched, None, resnet_feature_extractor),\n",
    "    (\"ResNet18 prediction softmax\", \"Partial Diffusion Ratio\", \"Softmax\", get_denoised_img_pred_scores, resnet_model, None),\n",
    ")\n",
    "plot_grid(prompt, mul_method, cuda_device, eval_set_size, \"resnet\", plot_cases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c8faeb1-dfd7-4542-a0f0-a91a65f32e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "efficientnet_model, efficientnet_feature_extractor = load_model(prompt, mul_method, eval_set_size, cuda_device, image_preprocessor, model_name='efficientnet')\n",
    "plot_cases = (\n",
    "    (\"EfficientNet Finetuned (Prefinal-layer)\", \"Partial Diffusion Ratio\", \"Cosine Similarity\", get_cosine_similarity, None, efficientnet_feature_extractor),\n",
    "    (\"EfficientNet Finetuned (Prefinal-layer)\", \"Partial Diffusion Ratio\", \"Mean Cosine Similarity\", get_cosine_similarity_batched, None, efficientnet_feature_extractor),\n",
    "    (\"EfficientNet prediction softmax\", \"Partial Diffusion Ratio\", \"Softmax\", get_denoised_img_pred_scores, efficientnet_model, None),\n",
    ")\n",
    "plot_grid(prompt, mul_method, cuda_device, eval_set_size, \"efficient\", plot_cases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45a81cc0-d036-4790-b36b-051ae82a9f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "densenet_model, densenet_feature_extractor = load_model(prompt, mul_method, eval_set_size, cuda_device, image_preprocessor, model_name='densenet')\n",
    "plot_cases = (\n",
    "    (\"DenseNet Finetuned (Prefinal-layer)\", \"Partial Diffusion Ratio\", \"Cosine Similarity\", get_cosine_similarity, None, densenet_feature_extractor),\n",
    "    (\"DenseNet Finetuned (Prefinal-layer)\", \"Partial Diffusion Ratio\", \"Mean Cosine Similarity\", get_cosine_similarity_batched, None, densenet_feature_extractor),\n",
    "    (\"DenseNet prediction softmax\", \"Partial Diffusion Ratio\", \"Softmax\", get_denoised_img_pred_scores, densenet_model, None),\n",
    ")\n",
    "plot_grid(prompt, mul_method, cuda_device, eval_set_size, \"dense\", plot_cases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f38b1944-163d-41ab-860f-42e0e1c737df",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_cases = (\n",
    "    (\"KID score trend\", \"Partial Diffusion Ratio\", \"KID Score\", calculate_kid_score, None, None),\n",
    ")\n",
    "plot_grid(prompt, mul_method, cuda_device, eval_set_size, \"other-metrics\", plot_cases)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
